{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "688aad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling page 1: http://books.toscrape.com/catalogue/page-1.html\n",
      "Crawling page 2: http://books.toscrape.com/catalogue/page-2.html\n",
      "Crawling page 3: http://books.toscrape.com/catalogue/page-3.html\n",
      "Crawling page 4: http://books.toscrape.com/catalogue/page-4.html\n",
      "Crawling page 5: http://books.toscrape.com/catalogue/page-5.html\n",
      "Web crawling completed. Data saved to 'products.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract product information from a single page\n",
    "def extract_products_from_page(url):\n",
    "    # Send a GET request to the page\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the page content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Empty list to hold product details\n",
    "    products = []\n",
    "    \n",
    "    # Find all product containers (each book is in an article tag with class 'product_pod')\n",
    "    product_containers = soup.find_all('article', class_='product_pod')\n",
    "    \n",
    "    for container in product_containers:\n",
    "        # Extract product name (book title is inside 'h3' tag)\n",
    "        name = container.find('h3').find('a')['title']\n",
    "        \n",
    "        # Extract product price (price is in a 'p' tag with class 'price_color')\n",
    "        price = container.find('p', class_='price_color').text.strip()\n",
    "        \n",
    "        # Extract product link (link to the book details page is inside the 'a' tag within 'h3')\n",
    "        link = container.find('h3').find('a')['href']\n",
    "        \n",
    "        # Construct full link if needed\n",
    "        full_link = f'http://books.toscrape.com/catalogue/{link}' if link.startswith('catalogue') else f'http://books.toscrape.com/{link}'\n",
    "        \n",
    "        # Append the product details to the products list\n",
    "        products.append({\n",
    "            'Name': name,\n",
    "            'Price': price,\n",
    "            'Link': full_link\n",
    "        })\n",
    "    \n",
    "    return products\n",
    "\n",
    "# Main function to crawl multiple pages\n",
    "def crawl_ecommerce_website(start_url, pages_to_crawl=5):\n",
    "    all_products = []\n",
    "    \n",
    "    for page in range(1, pages_to_crawl + 1):\n",
    "        # Construct the URL for the specific page\n",
    "        url = f'{start_url}catalogue/page-{page}.html'\n",
    "        print(f'Crawling page {page}: {url}')\n",
    "        \n",
    "        # Extract product data from the page\n",
    "        products = extract_products_from_page(url)\n",
    "        \n",
    "        # Add the products to the master list\n",
    "        all_products.extend(products)\n",
    "    \n",
    "    return all_products\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Start URL of the e-commerce website's product listing page\n",
    "    start_url = 'http://books.toscrape.com/'\n",
    "    \n",
    "    # Crawl 5 pages of the website\n",
    "    products = crawl_ecommerce_website(start_url, pages_to_crawl=5)\n",
    "    \n",
    "    # Convert the list of products into a pandas DataFrame\n",
    "    df = pd.DataFrame(products)\n",
    "    \n",
    "    # Output the DataFrame to a CSV file\n",
    "    df.to_csv('lab_5/products.csv', index=False)\n",
    "    \n",
    "    print(\"Web crawling completed. Data saved to 'products.csv'.\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9120ce4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Name    Price  \\\n",
      "0                   A Light in the Attic  Â£51.77   \n",
      "1                     Tipping the Velvet  Â£53.74   \n",
      "2                             Soumission  Â£50.10   \n",
      "3                          Sharp Objects  Â£47.82   \n",
      "4  Sapiens: A Brief History of Humankind  Â£54.23   \n",
      "\n",
      "                                                Link  \n",
      "0  http://books.toscrape.com/a-light-in-the-attic...  \n",
      "1  http://books.toscrape.com/tipping-the-velvet_9...  \n",
      "2  http://books.toscrape.com/soumission_998/index...  \n",
      "3  http://books.toscrape.com/sharp-objects_997/in...  \n",
      "4  http://books.toscrape.com/sapiens-a-brief-hist...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "file_path = 'C:/Users/ameyp/IR in AI Lab/lab_5/products.csv'\n",
    "\n",
    "try:\n",
    "    # Try to read the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Check if the file is empty\n",
    "    if data.empty:\n",
    "        print(\"The CSV file is empty.\")\n",
    "    else:\n",
    "        # Display the first five rows\n",
    "        print(data.head())\n",
    "\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"Error: The CSV file is empty or does not contain any valid data.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file at path '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e1473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
